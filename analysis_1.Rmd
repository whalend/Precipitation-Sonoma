---
title: "Sonoma precipitation data analysis1"
author: "whalen"
date: "November 18, 2014"
output: html_document
---

Outliers have been replaced with `NA` (see `explore_report.Rmd` for details). Here I load the datasets with the `NA`s inserted and start setting things up for analyses - thin plate spline and/or regression kriging.

Load libraries I plan to use for data manipulation (`dplyr`) and plotting (`ggplot2`).
```{r load basic libraries, echo=TRUE, message=FALSE}
library(ggplot2)
library(plyr)
library(dplyr)
```

Read-in the data sets, one daily and one hourly, and then plot. For outlier replacement in these data sets I settled on a daily precipitation threshold of greater than or equal to 6.5 inches, and an hourly precipitation threshold of greater than or equal to 2 inches.
```{r read in daily data, echo=TRUE}
dy_rg_data <- readRDS("dy_rg_data_corrected.rds")
summary(dy_rg_data)
str(dy_rg_data)
ggplot(data = dy_rg_data, aes(x = date, y = daily_ppt)) +
      geom_point()
```


```{r Exploratory plotting}
qplot(date, daily_ppt, data = dy_rg_data %>% 
            group_by(id, year, month, day), color = id) # + 
      # geom_text(aes(label=id),hjust=-0.1, vjust=0)

# Looking at precipitation by month during 2006
ggplot(data = dy_rg_data %>% 
            filter(year==2006) %>%
            group_by(id, year, month) %>%
            summarize(monthly_ppt=sum(daily_ppt)),
       aes(x = month, y = monthly_ppt, color = id)) +
      geom_point(size=2, shape=3)
```

Make data frame of monthly totals and plot across all years
```{r summarise daily to monthly totals, echo=TRUE, eval=FALSE}
# Monthly precipitation (ppt) by year, month, and gauge id
monthly_ppt_id <- dy_rg_data %>% 
      group_by(year, month, id) %>%# This grouping order causes reordering by year, month, then id
      summarise(monthly_ppt = sum(daily_ppt))
monthly_ppt_id
# Add date factor variable
monthly_ppt_id <- mutate(monthly_ppt_id, date = paste(year,"-",month, sep = ""))
# Convert date factor to `date` format for plotting
monthly_ppt_id$date <- as.Date(paste(monthly_ppt_id$date, "-01", sep=""))


# Aggregate to mean monthly precip across all gauges, so exclude id from the data frame `monthly_ppt_id`
monthly_ppt <- monthly_ppt_id %>%
      group_by(year, month, date) %>%
      summarise(avg_monthly_ppt = mean(monthly_ppt, na.rm=TRUE))
summary(monthly_ppt)
filter(monthly_ppt, is.na(avg_monthly_ppt))
filter(monthly_ppt_id, year == 2003, month == 4 | month == 1)
```

Plot monthly rainfall data
```{r plotting monthly data, echo=TRUE, eval=FALSE, fig.height=9, fig.width=6}
# Plot monthly rainfall grouped by plot ####
mp_id <- ggplot(data = monthly_ppt_id %>%
            filter(id == "cook" | id == "kunde" | id == "sawi"),
            #group_by(id),
       aes(x = date, y = monthly_ppt, color = id)) + 
      geom_point(size=2) +
      ylab("rainfall (inches)")

library(scales)
mp_id + facet_grid(id ~ ., scales = "fixed") + 
      theme_bw() + theme(legend.position = "none") +
      scale_x_date(breaks = date_breaks("6 months"), 
                   labels = date_format("%m/%y"),
                   minor_breaks = "1 month") +
      xlab("date (month/year)") + ggtitle("Total Monthly Rainfall 2004-2013")
ggsave("figures/mp_id.svg", width = 7, height = 5, scale = 1.5)
# mp + geom_boxplot()
# Adjust the way the date is scaled on the x-axis
#mp + scale_x_date(date)

# Plot monthly data averaged across plots
mp <- ggplot(data = monthly_ppt,
            #filter(id == "cook" | id == "kunde" | id == "sawi"),
            #group_by(id),
       aes(x = date, y = avg_monthly_ppt)) + 
      geom_point(size=2) +
      ylab("rainfall (inches)")

library(scales)
mp + geom_line() +
      theme_bw() + theme(legend.position = "none") +
      scale_x_date(breaks = date_breaks("1 year"), 
                   labels = date_format("%m/%y"),
                   minor_breaks = "1 month") +
      xlab("date (month/year)") + ggtitle("Average Monthly Rainfall 2004-2013")
ggsave("figures/avg_mp.svg", width = 7, height = 5, scale = 1.5)
```

```{r export plot to file, echo=TRUE, eval=TRUE}
# `ggsave` exports the current `ggplot` object
ggsave("figures/avg_mp.svg", width = 7, height = 5, scale = 1.5)
```


I also have data at an hourly resolution, but am not going to work with that for now
```{r hourly data, eval=FALSE, echo=TRUE}
hr_rg_data <- readRDS("hr_rg_data.rds")
summary(hr_rg_data)
qplot(id, hourly_ppt, data=hr_rg_data)
#Replace hourly_ppt values >= 1 inch
hr_rg_data$hourly_ppt[hr_rg_data$hourly_ppt>=1] <- NA

qplot(month, monthly_ppt, data = hr_rg_data %>%
      filter(year==2006) %>%
            group_by(id, year, month) %>%
            summarize(monthly_ppt=sum(hourly_ppt)), color = id,
      main="Monthly total from hourly data - 2006")
```

I want to group the daily data into data frames by month and year so that I can create an interpolation for precipitation for each unique month-year combination from each location. For example:
```{r group by year month, echo=TRUE}
ppt2004_01 <- dy_rg_data %>% #
      group_by(id, year, month) %>% 
      filter(year==2004, month==1) %>%
      summarise(monthly_ppt = sum(daily_ppt))
ppt2004_01
```

This is how I need each data frame to be structured, but I want to find a faster way to create the whole set of month-year combinations
```{r list of data frames split by month-year, echo=TRUE}
# Make a data frame of monthly totals for each year-month-location combination
monthly_ppt <- dy_rg_data %>%
      group_by(year, month, id) %>%
      summarise(monthly_ppt = sum(daily_ppt))
monthly_ppt

# Split that dataframe on the month and year to create a list of data frames with the total precipitation and location id for each month and year combo
df_list <- split(monthly_ppt, list(monthly_ppt$year, monthly_ppt$month))# 132 data frames
```

I wasn't sure what to do from here in trying to put each data frame into the global environment. I finally hit on the right search terms ("unlist data frame R") revealing this function in an answer on [Stack Overflow](http://stackoverflow.com/questions/17697239/r-unlist-a-list-of-dataframes):
```{r unlist data frames into environment, eval=FALSE}
list2env(df_list, .GlobalEnv))
```

Trying to figure out a `plyr` approach with `assign` so that I can name the data frames, but not having much luck.
```{r plyr unlist (fail), echo=FALSE, eval=FALSE}
# ldply(df_list, function(i){
#       assign(df_list[i], df_list[[i]])
# })
```
Two commenters asked why you would even want to do this when you could just work on them as elements of the list. Can I match up the spatial data to the data frames in the list? Then can I also pass each data frame in that list to an interpolation function?

I am leaving the data frames in the list for now.

I was working on trying to subset the named list of dataframes using wildcards/regular expressions (`regexp`). I wanted to break them up by year due to relocation of some rain gauges, so this is necessary to make sure the data is joined to the correct coordinates. Rain gauges typically were not moved very far, so it may not matter much, but I am being thorough.

I figured out how to do it using regular expressions. 
```{r subset list using regular expression, echo=TRUE, eval=TRUE}
# These first two lines didn't get me anywhere
# l <- subset(df_list, df_list["*"]<=df_list["*2008"])
# Filter(function(x) length(x) > 3, l)

# I want to match on 200* EXCEPT 2009*, so the expression is matching on strings with anything following 200 except skipping the string if the next character is a 9.
df_list_names <- names(df_list)
l_names <- df_list_names[grep("200[^9]", df_list_names)]# Testing syntax
df_list_0408 <- df_list[grep("200[^9]", df_list_names)]# Making subsetted list

# I want to get the 2009-2011 data frames. The `|` operates as "or" in the expression, so I am matching on either of these three strings
df_list_0911 <- df_list[grep("2009|2010|2011", df_list_names)]# Making subsetted list

# And now the 2012-2014 data frames
l_names <- df_list_names[grep("2012|2013|2014", df_list_names)]
df_list_1214 <- df_list[grep("2012|2013|2014", df_list_names)]
```


A couple of rain gauges have been moved to new locations near their established areas over the years, so I have shapefiles corresponding the move of one or more gauge stations.
```{r list rain gague shapefiles}
list.files("shapefiles", pattern = "*.shp")
```
This shows that there are four shapefiles for various stretches of the study, 2003-2008, 2009-2011, 2012-2014, and then 2015 and beyond. The 2015 is the result of moving a rain gauge during our 2014 visits. I will not be using that file for the data I have in hand.

Develop variables of rainfall for each rainy season: number of days with rain `rainXX_dys`, average daily rainfall `rainXX_avg`, and total rainfall `rainXX_tot`.
```{r breakdown daily into seasonal aggregation, message=FALSE}
library(dplyr)
summary(filter(dy_rg_data, id == "glenellen"))

# Calculate number of days, average, total with recorded rain
dys_rain <- dy_rg_data %>% 
      filter(date >= "2003-11-01", date <= "2004-05-31", daily_ppt > 0) %>% 
      group_by(id) %>% 
      summarise(rain04_dys = length(daily_ppt), rain04_avg = mean(daily_ppt), rain04_tot = sum(daily_ppt))
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2004-11-01", date <= "2005-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain05_dys = length(daily_ppt), rain05_avg = mean(daily_ppt), rain05_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2005-11-01", date <= "2006-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain06_dys = length(daily_ppt), rain06_avg = mean(daily_ppt), rain06_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2006-11-01", date <= "2007-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain07_dys = length(daily_ppt), rain07_avg = mean(daily_ppt), rain07_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2007-11-01", date <= "2008-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain08_dys = length(daily_ppt), rain08_avg = mean(daily_ppt), rain08_tot = sum(daily_ppt)), by = "id", all = T)

dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2008-11-01", date <= "2009-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain09_dys = length(daily_ppt), rain09_avg = mean(daily_ppt), rain09_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2009-11-01", date <= "2010-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain10_dys = length(daily_ppt), rain10_avg = mean(daily_ppt), rain10_tot = sum(daily_ppt)), by = "id", all = T)

dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2010-11-01", date <= "2011-05-31", daily_ppt > 0) %>% 
      group_by(id) %>% 
      summarise(rain11_dys = length(daily_ppt), rain11_avg = mean(daily_ppt), rain11_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2011-11-01", date <= "2012-05-31", daily_ppt > 0) %>% 
      group_by(id) %>% 
      summarise(rain12_dys = length(daily_ppt), rain12_avg = mean(daily_ppt), rain12_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2013-11-01", date <= "2014-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain14_dys = length(daily_ppt), rain14_avg = mean(daily_ppt), rain14_tot = sum(daily_ppt)), by = "id", all = T)

summary(dys_rain)
```

I think that the `NAs` during some seasons are due to rain gauges not recording, recording bad data, or being decommissioned. 
```{r investigate dys_rain NAs}
filter(dys_rain, is.na(rain04_dys)) # mackie, glenellen x2 (3)
filter(dys_rain, is.na(rain06_dys)) # kunde, mitsui, sugarloaf, glenellen x2 (5)
filter(dys_rain, is.na(rain07_dys)) # fop, kunde, spaulding, glenellen x2 (5)
filter(dys_rain, is.na(rain08_dys)) # fop, glenellen x2 (3)
filter(dys_rain, is.na(rain09_dys)) # backman, cook, fop, mitsui (4)
filter(dys_rain, is.na(rain10_dys)) # fop, sugarloaf (2)
filter(dys_rain, is.na(rain11_dys)) # beltane, fop, mitsui, sugarloaf, votruba (5)
filter(dys_rain, is.na(rain12_dys)) # annadel, backman, beltane, fop, kunde, mitsui, sugarloaf, votruba (8)
filter(dys_rain, is.na(rain14_dys)) # annadel, badger, beltane, cook, fop, sawi, secret, spaulding, sugarloaf, votruba (10)
```
I noticed that the way the series of join statements were written I missed the "mackie" rain gauge because it was not part of the 2004 season. I corrected this and another join issue that arose later with adding the Glen Ellen rain gauges by calling the `merge` function with `all = TRUE` option. This is a "full outer join" that retains all the values for all the rows, inserting `NAs` for columns where the data is missing for that row. Here the rows correspond to the rain gauge station name.

I still need to investigate the very high maximum total rainfall for 2005. (From previously playing with this data I think I may find some other issues as well)
```{r investigate dys_rain extreme values}
filter(dys_rain, rain05_tot > 70)
select(dys_rain, id, rain05_tot)
```


```{r monthly data 2003-2008}
month_rg_2003_2008 <- dy_rg_data %>%
      group_by(id, year, month) %>% 
      filter(year<=2008) %>%
      summarise(monthly_ppt = sum(daily_ppt))
month_rg_2003_2008$id <- as.factor(month_rg_2003_2008$id)
summary(month_rg_2003_2008)

day_rg_2003_2008 <- dy_rg_data %>%
      group_by(year, month, day, id) %>%
      filter(year<=2008)
summary(day_rg_2003_2008)
```


```{r read in shapefile(s) and DEM}
library(sp)
library(raster)
library(rgdal)

rg_2003_2008 <- readOGR(dsn="shapefiles", layer="RainGauges2003_2008")
str(rg_2003_2008)
rg_2003_2008@data$NAME
unique(dys_rain$plotid)
rg_2003_2008@data$NAME <- tolower(rg_2003_2008@data$NAME)
rg_2003_2008@data$NAME[rg_2003_2008@data$NAME=="macki"] <- "mackie"
rg_2003_2008@data$NAME[rg_2003_2008@data$NAME=="sdc"] <- "sec"
rg_2003_2008@data$NAME[rg_2003_2008@data$NAME=="sugar"] <- "sugarloaf"
unique(rg_2003_2008@data$NAME)
plot(rg_2003_2008)
# rg_2003_2008@coords <- rg_2003_2008@coords[-7,] # remove coordinates for FOP
# plot(rg_2003_2008)
# rg_2003_2008@data <- filter(rg_2003_2008@data, NAME != "fop")

rg_2009_2011 <- readOGR(dsn = "shapefiles/", layer = "RainGauges2009_2011")
str(rg_2009_2011)
rg_2009_2011$NAME
rg_2009_2011$NAME <- tolower(rg_2009_2011$NAME)
rg_2009_2011@data$NAME[rg_2009_2011@data$NAME=="macki"] <- "mackie"
rg_2009_2011@data$NAME[rg_2009_2011@data$NAME=="sdc"] <- "sec"
rg_2009_2011@data$NAME[rg_2009_2011@data$NAME=="sugar"] <- "sugarloaf"

rg_2012_2014 <- readOGR(dsn = "shapefiles/", layer = "RainGauges2012_2014")
str(rg_2012_2014)
rg_2012_2014$NAME
rg_2012_2014$NAME <- tolower(rg_2012_2014$NAME)
rg_2012_2014@data$NAME[rg_2012_2014@data$NAME=="macki"] <- "mackie"
rg_2012_2014@data$NAME[rg_2012_2014@data$NAME=="sdc"] <- "sec"
rg_2012_2014@data$NAME[rg_2012_2014@data$NAME=="sugar"] <- "sugarloaf"

glen_ellen_rg <- readOGR("shapefiles/", "GlenEllen_ppt_2009-2015")
str(glen_ellen_rg)
glen_ellen_rg$station <- tolower(glen_ellen_rg$station)

# Load elevation raster and transform shapefiles to match projection
elev <- raster("dem/sod15m.tif")
str(elev)
crs <- elev@crs
rg_2003_2008 <- spTransform(rg_2003_2008, CRS=crs)
rg_2009_2011 <- spTransform(rg_2009_2011, CRS=crs)
rg_2012_2014 <- spTransform(rg_2012_2014, CRS=crs)
glen_ellen_rg <- spTransform(glen_ellen_rg, CRS=crs)

# Overlay rain gauge files on elevation grid. Elevation is in feet.
plot(elev)
plot(rg_2003_2008, pch = 25, col = "blue", bg="transparent", add=TRUE)
#spplot(elev, scales=list(draw=T), sp.layout=list("sp.points", rg_2003_2008))
plot(rg_2009_2011, pch = 20, col = "red", add = T)
plot(rg_2012_2014, pch = 2, add = T)
plot(glen_ellen_rg, add = T)
```

Now that everything is in the same projection, I want to append the Glen Ellen stations point shapefile to the point files of the other rain gauges.
```{r append/merge shapefiles}
library(rgeos)
library(maptools)

names(rg_2003_2008)[2:4] <- c("station","lat","lon")
rg_2003_2008@data <- select(rg_2003_2008@data, -NUM)

names(rg_2009_2011)[2:4] <- c("station","lat","lon")
rg_2009_2011@data <- select(rg_2009_2011@data, -NUM)
rg_2009_2011 <- spRbind(rg_2009_2011, glen_ellen_rg)
rg_2009_2011@data$lon <- rg_2009_2011@coords[,1]
rg_2009_2011@data$lat <- rg_2009_2011@coords[,2]

names(rg_2012_2014)[2:4] <- c("station","lat","lon")
rg_2012_2014@data <- select(rg_2012_2014@data, -NUM)
rg_2012_2014 <- spRbind(rg_2012_2014, glen_ellen_rg)
rg_2012_2014@data$lon <- rg_2012_2014@coords[,1]
rg_2012_2014@data$lat <- rg_2012_2014@coords[,2]
```

Extracting elevation values to the points
```{r extract elevation to points}
library(raster)
rg_2003_2008@data$elev_ft <- extract(elev, rg_2003_2008)
rg_2009_2011@data$elev_ft <- extract(elev, rg_2009_2011)
rg_2012_2014@data$elev_ft <- extract(elev, rg_2012_2014)
```

Joining seasonal precipitation data to spatial points data frame
```{r joining data}
detach("package:raster", unload=TRUE) # unmask `select` in `dplyr`
summary(dys_rain)

# inner_join(rg_2003_2008@data, dys_rain %>% select(-starts_with("rain1"), -contains("09")), by = c("NAME" = "plotid"))
rg_2003_2008@data <- inner_join(rg_2003_2008@data, dys_rain %>% select(-starts_with("rain1"), -contains("09")), by = c("station" = "id"))
rg_2003_2008@data$elev_m <- rg_2003_2008@data$elev_ft * .305
summary(rg_2003_2008)

rg_2009_2011@data <- inner_join(rg_2009_2011@data, dys_rain %>% select(id, contains("09"), contains("10"), contains("11")), by = c("station" = "id"))
rg_2009_2011@data$elev_m <- rg_2009_2011@data$elev_ft * .305
summary(rg_2009_2011)

rg_2012_2014@data <- inner_join(rg_2012_2014@data, dys_rain %>% select(id, contains("12"), contains("13"), contains("14")), by = c("station" = "id"))
rg_2012_2014@data$elev_m <- rg_2012_2014@data$elev_ft * .305
summary(rg_2012_2014)
```

Now I am going to create new datasets that are for each season
```{r filter data to each season}
rg_2003_2008@data
# mackie was missing from 2004, corresponding to row 10
rainy04 <- rg_2003_2008[rg_2003_2008$station != "mackie",]# remove mackie
rainy04@data <- rainy04@data %>% select(station, elev_ft, lat, lon, elev_m, starts_with("rain04"))
rainy04; summary(rainy04)

# None missing in 2005, but removed "beltane" (row 4) and "fop" (row 7) because severe positive outliers, recording > 70 and 109 inches of rain. The next highest was 44 inches
rainy05 <- rg_2003_2008[,c("station", "lat", "lon", "rain05_dys", "rain05_avg", "rain05_tot", "elev_m")]
rainy05 <- rainy05[rainy05$station != "beltane" & rainy05$station != "fop",]
rainy05@data; summary(rainy05)

rainy06 <- rg_2003_2008[,c("station", "lat", "lon", "rain06_dys", "rain06_avg", "rain06_tot", "elev_m")]
rainy06@data # In 2006 there are some NAs and also some very small values (<2 inches) that seem extremely unreliable compared to the other measurements. I'm not really sure what to do about those
rainy06 <- rainy06[rainy06$station == "annadel" | rainy06$station == "cook" | rainy06$station == "fop" | rainy06$station == "mackie" | rainy06$station == "spaulding" | rainy06$station == "votruba" | rainy06$station == "yahng",]
rainy06@data; summary(rainy06); plot(rainy06)
# This results in essentially zero coverage in the southeastern part of the study area

rainy07 <- rg_2003_2008[,c("station", "lat", "lon", "rain07_dys", "rain07_avg", "rain07_tot", "elev_m")]
rainy07@data # Again some NAs and values that don't seem very reliable
rainy07 <- rainy07[rainy07$station != "mitsui" & rainy07$station != "fop" & rainy07$station != "kunde" & rainy07$station != "spaulding",]
rainy07@data; summary(rainy07); plot(rainy07)

rainy08 <- rg_2003_2008[,c("station", "lat", "lon", "rain08_dys", "rain08_avg", "rain08_tot", "elev_m")]
rainy08@data
rainy08 <- rainy08[rainy08$station != "badger" & rainy08$station != "fop" & rainy08$station != "kunde" & rainy08$station != "spaulding",]
rainy08@data; summary(rainy08); plot(rainy08)

rainy09 <- rg_2009_2011[,c("station", "lat", "lon", "rain09_dys", "rain09_avg", "rain09_tot", "elev_m")]
rainy09@data
rainy09 <- rainy09[rainy09$station != "backman" & rainy09$station != "beltane" & rainy09$station != "mitsui" & rainy09$station != "cook",]
rainy09@data; summary(rainy09); plot(rainy09)

rainy10 <- rg_2009_2011[,c("station", "lat", "lon", "rain10_dys", "rain10_avg", "rain10_tot", "elev_m")]
rainy10@data
rainy10 <- rainy10[rainy10$station != "backman" & rainy10$station != "sugarloaf" & rainy10$station != "mitsui" & rainy10$station != "sec" & rainy10$station != "spaulding" & rainy10$station != "annadel",]
rainy10@data; summary(rainy10); plot(rainy10)

rainy11 <- rg_2009_2011[,c("station", "lat", "lon", "rain11_dys", "rain11_avg", "rain11_tot", "elev_m")]
rainy11@data
rainy11 <- rainy11[rainy11$station != "beltane" & rainy11$station != "sugarloaf" & rainy11$station != "mitsui" & rainy11$station != "votruba" & rainy11$station != "yahng",]
rainy11@data; summary(rainy11); plot(rainy11)

rainy12 <- rg_2012_2014[,c("station", "lat", "lon", "rain12_dys", "rain12_avg", "rain12_tot", "elev_m")]
rainy12@data
rainy12 <- rainy12[rainy12$station != "annadel" & rainy12$station != "backman" & rainy12$station != "kunde" & rainy12$station != "mitsui" & rainy12$station != "sugarloaf",]
rainy12@data; summary(rainy12); plot(rainy12)

rainy14 <- rg_2012_2014[,c("station", "lat", "lon", "rain14_dys", "rain14_avg", "rain14_tot", "elev_m")]
rainy14@data
rainy14 <- rainy14[rainy14$station == "backman" | rainy14$station == "mackie" | rainy14$station == "sec" | rainy14$station == "glenellen" | rainy14$station == "glenellenwnw",]
rainy14@data; summary(rainy14); plot(rainy14)

extent(rainy14); extent(rainy05); extent(elev) # note that extents are variable

writeOGR(rainy04, dsn = "shapefiles/", layer = "rain_gauges04", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy05, dsn = "shapefiles/", layer = "rain_gauges05", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy06, dsn = "shapefiles/", layer = "rain_gauges06", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy07, dsn = "shapefiles/", layer = "rain_gauges07", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy08, dsn = "shapefiles/", layer = "rain_gauges08", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy09, dsn = "shapefiles/", layer = "rain_gauges09", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy10, dsn = "shapefiles/", layer = "rain_gauges10", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy11, dsn = "shapefiles/", layer = "rain_gauges11", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy12, dsn = "shapefiles/", layer = "rain_gauges12", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy14, dsn = "shapefiles/", layer = "rain_gauges14", driver = "ESRI Shapefile", overwrite_layer = T)
```


Plotting precipitation against elevation for a subset of the data
```{r plot elevation vs precip}
library(ggplot2)

qplot(elev_ft, rain08_tot, data = rg_2003_2008@data, main = "2008 Rainfall") +
      geom_text(aes(label=NAME),hjust=-0.1, vjust=0)

qplot(elev_ft, rain04_tot, data = rg_2003_2008@data, color = NAME, main = "2004 Rainfall")

qplot(elev_ft, rain05_tot, data = rg_2003_2008@data, color = NAME, main = "2005 Rainfall") + geom_text(aes(label=NAME),hjust=-0.1, vjust=0)

cor(rg_2003_2008@data$elev_ft, rg_2003_2008@data$rain08_tot, use = "na.or.complete")
```

This shows minimal correlation between elevation and rainfall, however, I wonder how much the distance to coast is affecting this relationship. It is likely that these data may be bimodal in the precipitation~elevation relationship due to the rainshadowing of the Sonoma Valley and possibly to some extent the Mayacamas by Sonoma Mountain.

Here I am exploring the relationship between precipitation and longitude, assuming longitude as a proxy for distance to the coast in this case.
```{r plot longitude vs precip}
qplot(lon, rain04_tot, data = rg_2003_2008@data, main = "2004 Rainfall vs Distance to Coast") +
      geom_text(aes(label=NAME),hjust=-0.1, vjust=0)

qplot(lon, rain05_tot, data = rg_2003_2008@data, main = "2005 Rainfall vs Distance to Coast") +
      geom_text(aes(label=NAME),hjust=-0.1, vjust=0)

qplot(lon, rain06_tot, data = rg_2003_2008@data, main = "2006 Rainfall vs Distance to Coast") +
      geom_text(aes(label=NAME),hjust=-0.1, vjust=0)
qplot(date, daily_ppt, data = dy_rg_data %>% filter(year==2006), facets = id ~ ., main = "Daily Rainfall - 2006")

qplot(lon, rain07_tot, data = rg_2003_2008@data, main = "2007 Rainfall vs Distance to Coast") +
      geom_text(aes(label=NAME),hjust=-0.1, vjust=0)

qplot(lon, rain08_tot, data = rg_2003_2008@data, main = "2008 Rainfall vs Distance to Coast") +
      geom_text(aes(label=NAME),hjust=-0.1, vjust=0)

qplot(lon, elev_ft, data = rg_2003_2008@data) +
      geom_text(aes(label=NAME),hjust=-0.1, vjust=0)
```

``` {r panel functions for pairs}

panel.hist <- function(x, ...){
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...){
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

cor(rg_2003_2008@data$EASTING, rg_2003_2008@data$rain08_tot, use = "na.or.complete")
pairs(na.omit(rg_2003_2008@data %>% select(-starts_with("N")), -elev_m), diag.panel = panel.hist, lower.panel = panel.cor, upper.panel = panel.smooth)
```

Create Thiessen Polygon surfaces with rainfall values
```{r Thiessen Polygons}
# The `voronoi function from the `dismo` package, which was adapted from the code by Carson Farmer
library(dismo)
v1 <- voronoi(rg_2003_2008)
summary(v1)
v1@data$NAME
(v1@data)
plot(v1, axes = TRUE)

# From jbaums comment here: http://w3facility.org/question/how-to-create-thiessen-polygons-from-points-using-r-packages/
# They link to this site: http://carsonfarmer.com/?p=455, but I can't find the post/place where he wrote the original function.

# Carson's Voronoi polygons function
voronoipolygons <- function(x) {
  library(deldir)
  if (.hasSlot(x, 'coords')) {
    crds <- x@coords  
  } else crds <- x
  z <- deldir(crds[,1], crds[,2])
  w <- tile.list(z)
  polys <- vector(mode='list', length=length(w))
  require(sp)
  for (i in seq(along=polys)) {
    pcrds <- cbind(w[[i]]$x, w[[i]]$y)
    pcrds <- rbind(pcrds, pcrds[1,])
    polys[[i]] <- Polygons(list(Polygon(pcrds)), ID=as.character(i))
  }
  SP <- SpatialPolygons(polys)
  voronoi <- SpatialPolygonsDataFrame(SP, data=data.frame(x=crds[,1],
    y=crds[,2], row.names=sapply(slot(SP, 'polygons'), 
    function(x) slot(x, 'ID'))))
}

# rg0911 <- readOGR("shapefiles","RainGauges2009_2011")
# summary(rg0911)
# v <- voronoipolygons(rg0911)
# summary(v)
# plot(v)
# plot(rg0911, add = TRUE)
```

Proof that it works, but I think I need to subset for each season so that only points with observations are used. I should end up with 10 surfaces with varying numbers of polygons depending on how many sites were `NA` for that season.

```{r nearest point neighbor }
plts <- readOGR(dsn = "shapefiles", layer = "soco_plots_metric")
str(plts)
str(rainy04)
plts <- spTransform(plts, CRS=crs)
writeOGR(plts, dsn = "shapefiles/", layer = "soco_plots_lcc.shp", driver = "ESRI Shapefile", overwrite_layer = T)

lm04a <- lm(rain04_tot ~ EASTING + NORTHING + elev_ft, data = rainy04@data)
summary(lm04a)
par(mfrow = c(2,2))
plot(lm04a)

lm04b <- lm(rain04_dys ~ elev_ft + EASTING + NORTHING, data = rainy04@data)
summary(lm04b)
plot(lm04b)

lm04c <- lm(rain04_avg ~ elev_ft + EASTING, data = rainy04@data)
summary(lm04c)
plot(lm04c)

cor(rainy04@data$rain04_dys, rainy04@data$rain04_tot)
cor(rainy04@data$rain04_dys, rainy04@data$rain04_avg)
cor(rainy04@data$rain04_avg, rainy04@data$rain04_tot)

panel.hist <- function(x, ...){
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...){
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

pairs(rainy04@data %>% select(-NAME), lower.panel = panel.cor)
pairs(rainy05@data %>% select(-NAME), lower.panel = panel.cor)
```


```{r create season Thiessen polys}
library(rgdal); library(dismo)
rainy04v <- voronoi(rainy04 <- readOGR(dsn = "shapefiles", layer = "rain_gauges04"))
rainy05v <- voronoi(rainy05 <- readOGR(dsn = "shapefiles", layer = "rain_gauges05"))
rainy06v <- voronoi(rainy06 <- readOGR(dsn = "shapefiles", layer = "rain_gauges06"))
rainy07v <- voronoi(rainy07 <- readOGR(dsn = "shapefiles", layer = "rain_gauges07"))
rainy08v <- voronoi(rainy08 <- readOGR(dsn = "shapefiles", layer = "rain_gauges08"))
plot(rainy08v); rainy08v@bbox
```

Overlay Thiessen polygons and plot locations
```{r overlay plots and Thiessen polys}
library(rgdal)
plts <- readOGR(dsn = "shapefiles", layer = "soco_plots_metric")
str(plts)
str(rainy04)
plts <- spTransform(plts, CRS=crs)
all.equal.default(proj4string(plts), proj4string(rainy04v), proj4string(rainy05v))
plot(elev); plot(plts, add = TRUE, pch = 21); plot(rainy04v, axes = TRUE, add=T) 

rainy04v@bbox; plts@bbox; rg_2003_2008@bbox; elev@extent

str(rainy05v)
plot(rainy05v, axes = TRUE, main = "2005 Rain Thiessens"); plot(plts, add = TRUE); plot(rainy05, add = T, col = "blue", pch = 25)

plot(rainy06v, axes = TRUE, main = "2006 Rain Thiessens"); plot(plts, add = TRUE); plot(rainy06, add = T, col = "blue", pch = 25)

plot(rainy07v, axes = TRUE, main = "2007 Rain Thiessens"); plot(plts, add = TRUE); plot(rainy07, add = T, col = "blue", pch = 25)

plot(rainy08v, axes = TRUE, main = "2008 Rain Thiessens"); plot(plts, add = TRUE); plot(rainy08, add = T, col = "blue", pch = 25)
```


Developing a linear model for kriging
```{r rk model jan 2008}
rg_0108 <- subset(rg_2003_2008@data, year==2008 & month==1)
coordinates(rg_0108) = ~NORTHING+EASTING
str(rg_0108)
#rg_2003_2008 <- readOGR(dsn="shapefiles", layer="RainGauges2003_2008")
#rg_2003_2008 <- spTransform(rg_2003_2008, CRS=crs)
rg_0108@proj4string <- rg_2003_2008@proj4string
rg_0108 <- spTransform(rg_0108, CRS=crs)

# elev_ppt <- overlay(as(elev, "SpatialGridDataFrame"), rg_0108)   # create grid-points overlay
   # copy the slope values
lm_rg_0108 <- lm(daily_ppt ~ elev_m, rg_0108)# This is certainly incorrect b/c precipitation constrained to be >= 0 
summary(lm_rg_0108)
plot(lm_rg_0108)

plot(log(rg_0108$elev_m), log1p(rg_0108$daily_ppt))
lm_rg_0108a <- lm((daily_ppt) ~ elev_m, data = rg_0108@data %>% filter(NAME != "backman", day == 31))
summary(lm_rg_0108a)
```


```{r thin plate spline example}
library(fields)
loc_matrix <- cbind(rg_0108$NORTHING,rg_0108$EASTING)
ppt <- (rg_0108$daily_ppt)
jan08tps <- Tps(loc_matrix, ppt)
summary(jan08tps)
plot(jan08tps)
surface(jan08tps)

look <- predict(jan08tps, lambda = 2.0)
look <- predict(jan08tps, df = 4)

tps1 <- Tps(loc_matrix, ppt, df = 4)
summary(tps1)
set.panel(2,2)
plot(tps1)
set.panel()

out_jan08 <- predictSurface(jan08tps)
image(out_jan08)

# fit <- Tps(ozone$x, ozone$y)
# set.panel(2,2)
# plot(fit)
```
