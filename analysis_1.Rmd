---
title: "Sonoma precipitation data analysis1"
author: "whalen"
date: "November 18, 2014"
output: html_document
---

Outliers have been replaced with `NA` (see `explore_report.Rmd` for details). Here I load the datasets with the `NA`s inserted and start setting things up for analyses - thin plate spline and/or regression kriging.

Load libraries I plan to use for data manipulation (`dplyr`) and plotting (`ggplot2`).
```{r load libraries, echo=TRUE, message=FALSE}
library(ggplot2); library(plyr); library(dplyr)
```

Read-in the data sets, one daily and one hourly, and then plot. For outlier replacement in these data sets I settled on a daily precipitation threshold of greater than or equal to 6.5 inches, and an hourly precipitation threshold of greater than or equal to 2 inches.
```{r read in daily data, echo=TRUE}
dy_rg_data <- readRDS("dy_rg_data_corrected.rds")
summary(dy_rg_data)
str(dy_rg_data)
summary(filter(dy_rg_data, is.na(daily_ppt)))
ggplot(data = dy_rg_data, aes(x = date, y = daily_ppt)) +
      geom_point()
```


Make data frame of monthly totals and plot across all years
```{r summarise daily to monthly totals, echo=TRUE, eval=FALSE}
# Monthly precipitation (ppt) by year, month, and gauge id
monthly <- dy_rg_data %>% 
      group_by(id, year, month) %>%# This grouping order causes reordering by year, month, then id
      summarise(monthly_ppt = sum(daily_ppt), 
                monthly_ppt_mm = sum(daily_ppt) * 25.4)
monthly
# Add date factor variable
monthly <- mutate(monthly, date = paste(year,"-",month, sep = ""))
# Convert date factor to `date` format for plotting
monthly$date <- as.Date(paste(monthly$date, "-01", sep=""))
monthly

# Aggregate to mean monthly precip across all gauges, so exclude id from the data frame `monthly_ppt_id`
monthly_ppt <- monthly %>%
      group_by(year, month, date) %>%
      summarise(avg_monthly_ppt = mean(monthly_ppt, na.rm=TRUE))
summary(monthly_ppt)
filter(monthly_ppt, is.na(avg_monthly_ppt))
```

Plot total monthly rainfall data
```{r plotting monthly data, echo=TRUE, eval=FALSE, fig.height=9, fig.width=6}
# Plot monthly rainfall grouped by plot ####
# monthly_ppt <- ungroup(monthly_ppt)
mp_id <- ggplot(data = monthly, #%>%
            # filter(id == "cook" | id == "kunde" | id == "sawi"),
            # group_by(id),
       aes(x = date, y = monthly_ppt)) + 
      geom_point(size=2) +
      ylab("rainfall (inches)")

library(scales)
mp_id + 
      facet_grid(id ~ .) +
      theme_bw() + 
      theme(legend.position = "none") +
      scale_x_date(breaks = date_breaks("6 months"), 
                   labels = date_format("%m/%y"),
                   minor_breaks = "1 month") +
      xlab("date (month/year)") + ggtitle("Total Monthly Rainfall by Station 2004-2013")
ggsave("figures/mp_id.png", width = 7, height = 5, scale = 1.5)
# mp + geom_boxplot()
# Adjust the way the date is scaled on the x-axis
#mp + scale_x_date(date)

# Plot monthly data averaged across plots
mp <- ggplot(data = monthly_ppt,
            #filter(id == "cook" | id == "kunde" | id == "sawi"),
            #group_by(id),
       aes(x = date, y = avg_monthly_ppt)) + 
      geom_point(size=2) + geom_line() +
      ylab("rainfall (inches)")

library(scales)
mp + geom_line() +
      theme_bw() + theme(legend.position = "none") +
      scale_x_date(breaks = date_breaks("1 year"), 
                   labels = date_format("%m/%y"),
                   minor_breaks = "1 month") +
      xlab("date (month/year)") + ggtitle("Average Monthly Rainfall Across All Plots 2004-2013")
ggsave("figures/avg_mp.png", width = 7, height = 5, scale = 1.5)
```

```{r export plot to file, echo=TRUE, eval=TRUE}
# `ggsave` exports the current `ggplot` object
ggsave("figures/avg_mp.png", width = 7, height = 5, scale = 1.5)
```


I also have data at an hourly resolution, but am not going to work with that for now
```{r hourly data, eval=FALSE, echo=TRUE}
hr_rg_data <- readRDS("hr_rg_data.rds")
summary(hr_rg_data)
qplot(id, hourly_ppt, data=hr_rg_data)
#Replace hourly_ppt values >= 1 inch
hr_rg_data$hourly_ppt[hr_rg_data$hourly_ppt>=1] <- NA

qplot(month, monthly_ppt, data = hr_rg_data %>%
      filter(year==2006) %>%
            group_by(id, year, month) %>%
            summarize(monthly_ppt=sum(hourly_ppt)), color = id,
      main="Monthly total from hourly data - 2006")
```

I want to group the daily data into data frames by month and year so that I can create an interpolation for precipitation for each unique month-year combination from each location. For example:
```{r group by year month, echo=TRUE}
ppt2004_01 <- dy_rg_data %>% #
      group_by(id, year, month) %>% 
      #filter(year==2004, month==1) %>%
      summarise(monthly_ppt = sum(daily_ppt))
ppt2004_01
```

This is how I need each data frame to be structured, but I want to find a faster way to create the whole set of month-year combinations
```{r list of data frames split by month-year, echo=TRUE}
# Split `monthly` dataframe with year-month-location on the month and year to create a list of data frames with the total precipitation and location id for each month and year combo
df_list <- split(monthly, list(monthly$year, monthly$month))# 132 data frames
```

I wasn't sure what to do from here in trying to put each data frame into the global environment. I finally hit on the right search terms ("unlist data frame R") revealing this function in an answer on [Stack Overflow](http://stackoverflow.com/questions/17697239/r-unlist-a-list-of-dataframes):
```{r unlist data frames into environment, eval=FALSE}
list2env(df_list, .GlobalEnv))
```

Trying to figure out a `plyr` approach with `assign` so that I can name the data frames, but not having much luck.
```{r plyr unlist (fail), echo=FALSE, eval=FALSE}
# ldply(df_list, function(i){
#       assign(df_list[i], df_list[[i]])
# })
```
Two commenters asked why you would even want to do this when you could just work on them as elements of the list. Can I match up the spatial data to the data frames in the list? Then can I also pass each data frame in that list to an interpolation function?

I am leaving the data frames in the list for now.

I was working on trying to subset the named list of dataframes using wildcards/regular expressions (`regexp`). I wanted to break them up by year due to relocation of some rain gauges, so this is necessary to make sure the data is joined to the correct coordinates. Rain gauges typically were not moved very far, so it may not matter much, but I am being thorough.

I figured out how to do it using regular expressions. 
```{r subset list using regular expression, echo=TRUE, eval=TRUE}
# These first two lines didn't get me anywhere
# l <- subset(df_list, df_list["*"]<=df_list["*2008"])
# Filter(function(x) length(x) > 3, l)

# I want to match on 200* EXCEPT 2009*, so the expression is matching on strings with anything following 200 except skipping the string if the next character is a 9.
df_list_names <- names(df_list)
l_names <- df_list_names[grep("200[^9]", df_list_names)]# Testing syntax
df_list_0408 <- df_list[grep("200[^9]", df_list_names)]# Making subsetted list

# I want to get the 2009-2011 data frames. The `|` operates as "or" in the expression, so I am matching on either of these three strings
df_list_0911 <- df_list[grep("2009|2010|2011", df_list_names)]# Making subsetted list

# And now the 2012-2014 data frames
l_names <- df_list_names[grep("2012|2013|2014", df_list_names)]
df_list_1214 <- df_list[grep("2012|2013|2014", df_list_names)]
```


A couple of rain gauges have been moved to new locations near their established areas over the years, so I have shapefiles corresponding the move of one or more gauge stations.
```{r list rain gague shapefiles}
list.files("shapefiles", pattern = "*.shp")
```
This shows that there are four shapefiles for various stretches of the study, 2003-2008, 2009-2011, 2012-2014, and then 2015_2016. The 2015 is the result of moving a rain gauge during our 2014 visits. I will not be using that file for the data I have in hand.

Develop variables of rainfall for each rainy season: number of days with rain `rainXX_dys`, average daily rainfall `rainXX_avg`, and total rainfall `rainXX_tot`.
```{r breakdown daily into seasonal aggregation, message=FALSE}
library(dplyr)
summary(filter(dy_rg_data, id == "glenellen"))

# Calculate number of days, average, total with recorded rain
dys_rain <- dy_rg_data %>% 
      filter(date >= "2003-11-01", date <= "2004-05-31", daily_ppt > 0) %>% 
      group_by(id) %>% 
      summarise(rain04_dys = length(daily_ppt), rain04_avg = mean(daily_ppt), rain04_tot = sum(daily_ppt))
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2004-11-01", date <= "2005-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain05_dys = length(daily_ppt), rain05_avg = mean(daily_ppt), rain05_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2005-11-01", date <= "2006-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain06_dys = length(daily_ppt), rain06_avg = mean(daily_ppt), rain06_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2006-11-01", date <= "2007-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain07_dys = length(daily_ppt), rain07_avg = mean(daily_ppt), rain07_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2007-11-01", date <= "2008-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain08_dys = length(daily_ppt), rain08_avg = mean(daily_ppt), rain08_tot = sum(daily_ppt)), by = "id", all = T)

dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2008-11-01", date <= "2009-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain09_dys = length(daily_ppt), rain09_avg = mean(daily_ppt), rain09_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2009-11-01", date <= "2010-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain10_dys = length(daily_ppt), rain10_avg = mean(daily_ppt), rain10_tot = sum(daily_ppt)), by = "id", all = T)

dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2010-11-01", date <= "2011-05-31", daily_ppt > 0) %>% 
      group_by(id) %>% 
      summarise(rain11_dys = length(daily_ppt), rain11_avg = mean(daily_ppt), rain11_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2011-11-01", date <= "2012-05-31", daily_ppt > 0) %>% 
      group_by(id) %>% 
      summarise(rain12_dys = length(daily_ppt), rain12_avg = mean(daily_ppt), rain12_tot = sum(daily_ppt)), by = "id", all = T)
      
dys_rain <- merge(dys_rain, dy_rg_data %>% 
      filter(date >= "2013-11-01", date <= "2014-05-31", daily_ppt > 0) %>% 
      group_by(id) %>%
      summarise(rain14_dys = length(daily_ppt), rain14_avg = mean(daily_ppt), rain14_tot = sum(daily_ppt)), by = "id", all = T)

summary(dys_rain)
```

I think that the `NAs` during some seasons are due to rain gauges not recording, recording bad data, or being decommissioned. 
```{r investigate dys_rain NAs}
filter(dys_rain, is.na(rain04_dys)) # mackie, glenellen x2 (3)
filter(dys_rain, is.na(rain06_dys)) # kunde, mitsui, sugarloaf, glenellen x2 (5)
filter(dys_rain, is.na(rain07_dys)) # fop, kunde, spaulding, glenellen x2 (5)
filter(dys_rain, is.na(rain08_dys)) # fop, glenellen x2 (3)
filter(dys_rain, is.na(rain09_dys)) # backman, cook, fop, mitsui (4)
filter(dys_rain, is.na(rain10_dys)) # fop, sugarloaf (2)
filter(dys_rain, is.na(rain11_dys)) # beltane, fop, mitsui, sugarloaf, votruba (5)
filter(dys_rain, is.na(rain12_dys)) # annadel, backman, beltane, fop, kunde, mitsui, sugarloaf, votruba (8)
filter(dys_rain, is.na(rain14_dys)) # annadel, badger, beltane, cook, fop, sawi, secret, spaulding, sugarloaf, votruba (10)
```
I noticed that the way the series of join statements were written I missed the "mackie" rain gauge because it was not part of the 2004 season. I corrected this and another join issue that arose later with adding the Glen Ellen rain gauges by calling the `merge` function with `all = TRUE` option. This is a "full outer join" that retains all the values for all the rows, inserting `NAs` for columns where the data is missing for that row. Here the rows correspond to the rain gauge station name.

I still need to investigate the very high maximum total rainfall for 2005. (From previously playing with this data I think I may find some other issues as well)
```{r investigate dys_rain extreme values}
filter(dys_rain, rain05_tot > 70)
select(dys_rain, id, rain05_tot)
```

```{r monthly data 2003-2008}
month_rg_2003_2008 <- dy_rg_data %>%
      group_by(id, year, month) %>% 
      filter(year<=2008) %>%
      summarise(monthly_ppt = sum(daily_ppt))
month_rg_2003_2008$id <- as.factor(month_rg_2003_2008$id)
summary(month_rg_2003_2008)

day_rg_2003_2008 <- dy_rg_data %>%
      group_by(year, month, day, id) %>%
      filter(year<=2008)
summary(day_rg_2003_2008)
```

```{r read in shapefile(s) and DEM}
library(sp)
library(raster)
library(rgdal)

rg_2003_2008 <- readOGR(dsn="shapefiles", layer="RainGauges2003_2008")
str(rg_2003_2008)
rg_2003_2008@data$NAME
unique(dys_rain$plotid)
rg_2003_2008@data$NAME <- tolower(rg_2003_2008@data$NAME)
rg_2003_2008@data$NAME[rg_2003_2008@data$NAME=="macki"] <- "mackie"
rg_2003_2008@data$NAME[rg_2003_2008@data$NAME=="sdc"] <- "sec"
rg_2003_2008@data$NAME[rg_2003_2008@data$NAME=="sugar"] <- "sugarloaf"
unique(rg_2003_2008@data$NAME)
plot(rg_2003_2008)
# rg_2003_2008@coords <- rg_2003_2008@coords[-7,] # remove coordinates for FOP
# plot(rg_2003_2008)
# rg_2003_2008@data <- filter(rg_2003_2008@data, NAME != "fop")

rg_2009_2011 <- readOGR(dsn = "shapefiles/", layer = "RainGauges2009_2011")
str(rg_2009_2011)
rg_2009_2011$NAME
rg_2009_2011$NAME <- tolower(rg_2009_2011$NAME)
rg_2009_2011@data$NAME[rg_2009_2011@data$NAME=="macki"] <- "mackie"
rg_2009_2011@data$NAME[rg_2009_2011@data$NAME=="sdc"] <- "sec"
rg_2009_2011@data$NAME[rg_2009_2011@data$NAME=="sugar"] <- "sugarloaf"

rg_2012_2014 <- readOGR(dsn = "shapefiles/", layer = "RainGauges2012_2014")
str(rg_2012_2014)
rg_2012_2014$NAME
rg_2012_2014$NAME <- tolower(rg_2012_2014$NAME)
rg_2012_2014@data$NAME[rg_2012_2014@data$NAME=="macki"] <- "mackie"
rg_2012_2014@data$NAME[rg_2012_2014@data$NAME=="sdc"] <- "sec"
rg_2012_2014@data$NAME[rg_2012_2014@data$NAME=="sugar"] <- "sugarloaf"

glen_ellen_rg <- readOGR("shapefiles/", "GlenEllen_ppt_2009-2015")
str(glen_ellen_rg)
glen_ellen_rg$station <- tolower(glen_ellen_rg$station)

# Load elevation raster and transform shapefiles to match projection
elev <- raster("dem/sod15m.tif")
str(elev)
crs <- elev@crs
rg_2003_2008 <- spTransform(rg_2003_2008, CRS=crs)
rg_2009_2011 <- spTransform(rg_2009_2011, CRS=crs)
rg_2012_2014 <- spTransform(rg_2012_2014, CRS=crs)
glen_ellen_rg <- spTransform(glen_ellen_rg, CRS=crs)

# Overlay rain gauge files on elevation grid. Elevation is in feet.
plot(elev)
plot(rg_2003_2008, pch = 25, col = "blue", bg="transparent", add=TRUE)
#spplot(elev, scales=list(draw=T), sp.layout=list("sp.points", rg_2003_2008))
plot(rg_2009_2011, pch = 20, col = "red", add = T)
plot(rg_2012_2014, pch = 2, add = T)
plot(glen_ellen_rg, add = T)
```

Now that everything is in the same projection, I want to append the Glen Ellen stations point shapefile to the point files of the other rain gauges.
```{r append/merge shapefiles}
library(rgeos)
library(maptools)

names(rg_2003_2008)[2:4] <- c("station","lat","lon")
rg_2003_2008@data <- select(rg_2003_2008@data, -NUM)

names(rg_2009_2011)[2:4] <- c("station","lat","lon")
rg_2009_2011@data <- select(rg_2009_2011@data, -NUM)
rg_2009_2011 <- spRbind(rg_2009_2011, glen_ellen_rg)
rg_2009_2011@data$lon <- rg_2009_2011@coords[,1]
rg_2009_2011@data$lat <- rg_2009_2011@coords[,2]

names(rg_2012_2014)[2:4] <- c("station","lat","lon")
rg_2012_2014@data <- select(rg_2012_2014@data, -NUM)
rg_2012_2014 <- spRbind(rg_2012_2014, glen_ellen_rg)
rg_2012_2014@data$lon <- rg_2012_2014@coords[,1]
rg_2012_2014@data$lat <- rg_2012_2014@coords[,2]
```

Extracting elevation values to the points
```{r extract elevation to points}
library(raster)
rg_2003_2008@data$elev_ft <- extract(elev, rg_2003_2008)
rg_2009_2011@data$elev_ft <- extract(elev, rg_2009_2011)
rg_2012_2014@data$elev_ft <- extract(elev, rg_2012_2014)
```

Joining seasonal precipitation data to spatial points data frame
```{r joining data}
detach("package:raster", unload=TRUE) # unmask `select` in `dplyr`
summary(dys_rain)

# inner_join(rg_2003_2008@data, dys_rain %>% select(-starts_with("rain1"), -contains("09")), by = c("NAME" = "plotid"))
rg_2003_2008@data <- inner_join(rg_2003_2008@data, dys_rain %>% select(-starts_with("rain1"), -contains("09")), by = c("station" = "id"))
rg_2003_2008@data$elev_m <- rg_2003_2008@data$elev_ft * .305
summary(rg_2003_2008)

rg_2009_2011@data <- inner_join(rg_2009_2011@data, dys_rain %>% select(id, contains("09"), contains("10"), contains("11")), by = c("station" = "id"))
rg_2009_2011@data$elev_m <- rg_2009_2011@data$elev_ft * .305
summary(rg_2009_2011)

rg_2012_2014@data <- inner_join(rg_2012_2014@data, dys_rain %>% select(id, contains("12"), contains("13"), contains("14")), by = c("station" = "id"))
rg_2012_2014@data$elev_m <- rg_2012_2014@data$elev_ft * .305
summary(rg_2012_2014)
```

Now I am going to create new datasets that are for each season
```{r filter data to each season}
rg_2003_2008@data
# mackie was missing from 2004, corresponding to row 10
rainy04 <- rg_2003_2008[rg_2003_2008$station != "mackie",]# remove mackie
rainy04@data <- rainy04@data %>% select(station, elev_ft, lat, lon, elev_m, starts_with("rain04"))
rainy04@data$totppt_mm <- rainy04@data$rain04_tot * 25.4
rainy04; summary(rainy04)

# None missing in 2005, but removed "beltane" (row 4) and "fop" (row 7) because severe positive outliers, recording > 70 and 109 inches of rain. The next highest was 44 inches
rainy05 <- rg_2003_2008[,c("station", "lat", "lon", "rain05_dys", "rain05_avg", "rain05_tot", "elev_m")]
rainy05 <- rainy05[rainy05$station != "beltane" & rainy05$station != "fop",]
rainy05@data$totppt_mm <- rainy05@data$rain05_tot * 25.4
rainy05@data; summary(rainy05)

rainy06 <- rg_2003_2008[,c("station", "lat", "lon", "rain06_dys", "rain06_avg", "rain06_tot", "elev_m")]
rainy06@data # In 2006 there are some NAs and also some very small values (<2 inches) that seem extremely unreliable compared to the other measurements. I'm not really sure what to do about those
rainy06 <- rainy06[rainy06$station == "cook" | rainy06$station == "mackie" | rainy06$station == "spaulding" | rainy06$station == "votruba" | rainy06$station == "yahng",]
rainy06@data$totppt_mm <- rainy06@data$rain06_tot * 25.4
rainy06@data; summary(rainy06); plot(rainy06)
# This results in essentially zero coverage in the southeastern part of the study area

rainy07 <- rg_2003_2008[,c("station", "lat", "lon", "rain07_dys", "rain07_avg", "rain07_tot", "elev_m")]
rainy07@data # Again some NAs and values that don't seem very reliable
rainy07 <- rainy07[rainy07$station != "mitsui" & rainy07$station != "fop" & rainy07$station != "kunde" & rainy07$station != "spaulding" & rainy07$station != "mackie" & rainy07$station != "sugarloaf" & rainy07$station != "votruba" & rainy07$station != "cook",]
rainy07@data$totppt_mm <- rainy07@data$rain07_tot * 25.4
rainy07@data; summary(rainy07); plot(rainy07)

rainy08 <- rg_2003_2008[,c("station", "lat", "lon", "rain08_dys", "rain08_avg", "rain08_tot", "elev_m")]
rainy08@data
rainy08 <- rainy08[rainy08$station != "backman" & rainy08$station != "badger" & rainy08$station != "fop" & rainy08$station != "kunde" & rainy08$station != "spaulding",]
rainy08@data$totppt_mm <- rainy08@data$rain08_tot * 25.4
rainy08@data; summary(rainy08); plot(rainy08)

rainy09 <- rg_2009_2011[,c("station", "lat", "lon", "rain09_dys", "rain09_avg", "rain09_tot", "elev_m")]
rainy09@data
rainy09 <- rainy09[rainy09$station != "backman" & rainy09$station != "beltane" & rainy09$station != "mitsui" & rainy09$station != "cook",]
rainy09@data$totppt_mm <- rainy09@data$rain09_tot * 25.4
rainy09@data; summary(rainy09); plot(rainy09)

rainy10 <- rg_2009_2011[,c("station", "lat", "lon", "rain10_dys", "rain10_avg", "rain10_tot", "elev_m")]
rainy10@data
rainy10 <- rainy10[rainy10$station != "backman" & rainy10$station != "sugarloaf" & rainy10$station != "mitsui" & rainy10$station != "sec" & rainy10$station != "spaulding" & rainy10$station != "annadel",]
rainy10@data$totppt_mm <- rainy10@data$rain10_tot * 25.4
rainy10@data; summary(rainy10); plot(rainy10)

rainy11 <- rg_2009_2011[,c("station", "lat", "lon", "rain11_dys", "rain11_avg", "rain11_tot", "elev_m")]
rainy11@data
rainy11 <- rainy11[rainy11$station != "beltane" & rainy11$station != "sugarloaf" & rainy11$station != "mitsui" & rainy11$station != "votruba" & rainy11$station != "yahng",]
rainy11@data$totppt_mm <- rainy11@data$rain11_tot * 25.4
rainy11@data; summary(rainy11); plot(rainy11)

rainy12 <- rg_2012_2014[,c("station", "lat", "lon", "rain12_dys", "rain12_avg", "rain12_tot", "elev_m")]
rainy12@data
rainy12 <- rainy12[rainy12$station != "annadel" & rainy12$station != "backman" & rainy12$station != "kunde" & rainy12$station != "mitsui" & rainy12$station != "sugarloaf" & rainy12$station != "spaulding" & rainy12$station != "sec" & rainy12$station != "secret" & rainy12$station != "cook",]
rainy12@data$totppt_mm <- rainy12@data$rain12_tot * 25.4
rainy12@data; summary(rainy12); plot(rainy12)

rainy14 <- rg_2012_2014[,c("station", "lat", "lon", "rain14_dys", "rain14_avg", "rain14_tot", "elev_m")]
rainy14@data
rainy14 <- rainy14[rainy14$station == "backman" | rainy14$station == "mackie" | rainy14$station == "sec" | rainy14$station == "glenellen" | rainy14$station == "glenellenwnw",]
rainy14@data$totppt_mm <- rainy14@data$rain14_tot * 25.4
rainy14@data; summary(rainy14); plot(rainy14)

writeOGR(rainy04, dsn = "shapefiles/", layer = "rain_gauges04", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy05, dsn = "shapefiles/", layer = "rain_gauges05", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy06, dsn = "shapefiles/", layer = "rain_gauges06", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy07, dsn = "shapefiles/", layer = "rain_gauges07", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy08, dsn = "shapefiles/", layer = "rain_gauges08", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy09, dsn = "shapefiles/", layer = "rain_gauges09", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy10, dsn = "shapefiles/", layer = "rain_gauges10", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy11, dsn = "shapefiles/", layer = "rain_gauges11", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy12, dsn = "shapefiles/", layer = "rain_gauges12", driver = "ESRI Shapefile", overwrite_layer = T)
writeOGR(rainy14, dsn = "shapefiles/", layer = "rain_gauges14", driver = "ESRI Shapefile", overwrite_layer = T)
```


#### Pairs plots and linear models of seasonally aggregated data
```{r read in spatial data frames}
library(rgdal)
shp_list <- list.files("shapefiles", pattern = "^[rain_]")
shp_list <- grep(".shp$", shp_list, value = TRUE)
shp_list <- shp_list[1:10]

shp_list <- strsplit(shp_list, ".shp")
tmp <- strsplit(unlist(shp_list), "rain_gauges")
tmp <- unlist(tmp)
tmp <- tmp[seq(2, 20, 2)]

n = 4
for(shp in shp_list){
      assign(paste("rainy", "0", n, sep = ""), 
             readOGR(dsn = "shapefiles", layer = shp))
      n = n + 1
}
rainy10 <- rainy010; rainy11 <- rainy011 
rainy12 <- rainy012; rainy14 <- rainy013
rm(list = ls(pattern = "01"))
```

```{r pairs plots & linear models}
library(MuMIn)
panel.hist <- function(x, ...){
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...){
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

pairs(rainy04@data %>% select(-station, -elev_ft), lower.panel = panel.cor, diag.panel = panel.hist, main = "2004 Season") # strongest relationship between lon & total rainfall (0.63); total rainfall looks maybe slightly right skewed and is about equally correlated with lat & elev

lm04a <- lm(rain04_tot ~ lon + lat + elev_m, data = rainy04@data, na.action = "na.fail")
summary(lm04a)
par(mfrow = c(2,2)); plot(lm04a)
lm04sel <- dredge(lm04a, extra =  list("*" = function(x){
        s <- summary(x)
        c(Rsq = s$r.squared, adjRsq = s$adj.r.squared,
            F = s$fstatistic[[1]])
    })); lm04sel
# Including elevation improves adjusted R-squared by about 9% and essentially has no change to AICc (0.4)

pairs(rainy05@data %>% select(-station), lower.panel = panel.cor, diag.panel = panel.hist, main = "2005 Season") # strongest relationship between lat & total rainfall (0.61); of note: lat & rainy days (0.70), lon & average rainfall(0.66)
lm05a <- lm(rain05_tot ~ lat + elev_m + lon, data = rainy05@data, na.action = "na.fail")
summary(lm05a)
par(mfrow = c(2,2)); plot(lm05a)
lm05sel <- dredge(lm05a, extra = list("*" = function(x) {
        s <- summary(x)
        c(Rsq = s$r.squared, adjRsq = s$adj.r.squared,
            F = s$fstatistic[[1]])
    })); lm05sel
# Best explanatory power and AICc with just latitude for this year

pairs(rainy06@data %>% select(-station), lower.panel = panel.cor, diag.panel = panel.hist, main = "2006 Season") # strongest relationship between lat & total rainfall (0.68), lon & total rainfall (0.67), elev & total rainfall (0.29); lat & lon (0.66), but I think this is because of the limited coverage being clustered to the NW quadrant of study area. Distributions are pretty uniform and there is not much variation within the measurements for this much reduced data.
lm06a <- lm(rain06_tot ~ lat + lon + elev_m, data = rainy06@data, na.action = "na.fail")
summary(lm06a)
par(mfrow = c(2,2)); plot(lm06a) # These diagnostic plots look terrible
lm06sel <- dredge(lm06a, extra = list("*" = function(x) {
        s <- summary(x)
        c(Rsq = s$r.squared, adjRsq = s$adj.r.squared,
            F = s$fstatistic[[1]])
    })); lm06sel
# 

pairs(rainy07@data %>% select(-station), lower.panel = panel.cor, diag.panel = panel.hist, main = "2007 Season") # strongest relationship between elev & total rainfall (0.52), though total rainfall looks like it has some negative skew;
lm07a <- lm(rain07_tot^4 ~ lat + lon + elev_m, data = rainy07@data, na.action = "na.fail")
summary(lm07a)
par(mfrow = c(2,2)); plot(lm07a) # Poor fitting model with adjusted r-squared negative
lm07sel <- dredge(lm07a, extra = list("*" = function(x) {
        s <- summary(x)
        c(Rsq = s$r.squared, adjRsq = s$adj.r.squared,
            F = s$fstatistic[[1]])
    })); lm07sel
# Best fit of a set of poor choices is elevation as only predictor. Transforming total rainfall by raising to the 4th power improves r-squared, but does not improve on the null model when AICc is compared (it's actually a little worse than the null model).

pairs(rainy08@data %>% select(-station), lower.panel = panel.cor, diag.panel = panel.hist, main = "2008 Season") # strongest relationship between lat & total rainfall (0.33)
lm08a <- lm(rain08_tot ~ lat + lon + elev_m, data = rainy08@data, na.action = "na.fail")
summary(lm08a)
par(mfrow = c(2,2)); plot(lm08a) # Poor model with adjusted r-squared negative
lm08sel <- dredge(lm08a, extra = list("*" = function(x) {
        s <- summary(x)
        c(Rsq = s$r.squared, adjRsq = s$adj.r.squared,
            F = s$fstatistic[[1]])
    })); lm08sel
# Latitude is best predictor of set of crappy models, but not better than the null model, i.e. no better than the average

pairs(rainy09@data %>% select(-station), lower.panel = panel.cor, diag.panel = panel.hist, main = "2009 Season") # weak correlation between total rainfall & lat/lon
lm09a <- lm(rain09_tot ~ lat + lon + elev_m, data = rainy09@data, na.action = "na.fail")
summary(lm09a)
par(mfrow = c(2,2)); plot(lm09a) # Poor model with adjusted r-squared negative
lm09sel <- dredge(lm09a, extra = list("*" = function(x) {
        s <- summary(x)
        c(Rsq = s$r.squared, adjRsq = s$adj.r.squared,
            F = s$fstatistic[[1]])
    })); lm09sel
# Again, latitude is best from a set of crappy models, but adjusted r-squared is negative, so not better than the null model, i.e. the population average

pairs(rainy10@data %>% select(-station), lower.panel = panel.cor, diag.panel = panel.hist, main = "2010 Season") # correlation between total rainfall & lat (0.51)
lm10a <- lm(rain10_tot ~ lat + lon + log(elev_m), data = rainy10@data, na.action = "na.fail")
summary(lm10a)
par(mfrow = c(2,2)); plot(lm10a) # Substantial explanatory power in this model
lm10sel <- dredge(lm10a, extra = list("*" = function(x) {
        s <- summary(x)
        c(Rsq = s$r.squared, adjRsq = s$adj.r.squared,
            F = s$fstatistic[[1]])
    })); lm10sel
# Best model combined AICc & adj.Rsquared (0.65) has elevation & latitude when elevation is log-transformed

pairs(rainy11@data %>% select(-station), lower.panel = panel.cor, diag.panel = panel.hist, main = "2011 Season") # Correlation between total rainfall & elevation 0.25
lm11a <- lm(rain11_tot ~ lat + lon + elev_m, data = rainy11@data, na.action = "na.fail")
summary(lm11a)
par(mfrow = c(2,2)); plot(lm11a) # Poor model with adjusted r-squared negative
lm11sel <- dredge(lm11a, extra = list("*" = function(x) {
        s <- summary(x)
        c(Rsq = s$r.squared, adjRsq = s$adj.r.squared,
            F = s$fstatistic[[1]])
    })); lm11sel
# Nothing any better than the null model, all adjusted R-squared are negative

pairs(rainy12@data %>% select(-station), lower.panel = panel.cor, diag.panel = panel.hist, main = "2012 Season") # weak correlation between total rainfall & elevation
lm12a <- lm(rain12_tot ~ lat + lon + elev_m, data = rainy12@data, na.action = "na.fail")
summary(lm12a)
par(mfrow = c(2,2)); plot(lm12a) # Poor model with adjusted r-squared negative
lm12sel <- dredge(lm12a, extra = list("*" = function(x) {
        s <- summary(x)
        c(Rsq = s$r.squared, adjRsq = s$adj.r.squared,
            F = s$fstatistic[[1]])
    })); lm12sel
# Nothing any better than the null model, all adjusted R-squared are negative

pairs(rainy14@data %>% select(-station), lower.panel = panel.cor, diag.panel = panel.hist, main = "2014 Season") # correlation between total rainfall & elev (0.70), total rainfall & lon (0.48)
lm14a <- lm(log(rain14_tot) ~ log(elev_m) + lon + lat, data = rainy14@data, na.action = "na.fail")
summary(lm14a)
par(mfrow = c(2,2)); plot(lm14a) # Poor model with small sample size
lm14sel <- dredge(lm14a, extra = list("*" = function(x) {
        s <- summary(x)
        c(Rsq = s$r.squared, adjRsq = s$adj.r.squared,
            F = s$fstatistic[[1]])
    })); lm14sel
# Best adjusted R-squared is with log(elevation), lat, lon (0.61) and total rainfall log-transformed, however, this is sample size of 5 stations. The variation of total rainfall is pretty limited.
```

There are some cases where the data have good coverage and a good fitting model and other seasons where nothing predicts better than the null model. So, I'm not sure if there are some years where I might be able to, or should, try and model a surface. The many factors that influence rainfall measurements over space and time 

  - wind speed and direction (difficult to measure everywhere)
  - gauge placement (human error)
  - elevation/topography
  
Due to the randomness of rainfall over even small areas, the best-practice approach for rainfall modeling is to sample an area as densely as possible and then apply Thiessen polygons. Or, I could try to do a nearest point data extraction for each plot. I think this works for years when there is data from stations throughout the study area (good spatial coverage), but I don't think this would work well when coverage is for only part, or very minimal of the study area. I need to read and understand more about thin plate splines to see if that might be applicable to these data.

(It seems that there is the possibility that these data are bimodal in the precipitation~elevation relationship due to the rainshadowing of the Sonoma Valley and possibly to some extent the Mayacamas by Sonoma Mountain.)


Create Thiessen Polygon surfaces with rainfall values
```{r Thiessen polygons test}
# The `voronoi function from the `dismo` package, which was adapted from the code by Carson Farmer
library(dismo)
v1 <- voronoi(rg_2003_2008)
summary(v1)
v1@data$station
(v1@data)
plot(v1, axes = TRUE)

# From jbaums comment here: http://w3facility.org/question/how-to-create-thiessen-polygons-from-points-using-r-packages/
# They link to this site: http://carsonfarmer.com/?p=455, but I can't find the post/place where he wrote the original function.

# Carson's Voronoi polygons function
voronoipolygons <- function(x) {
  library(deldir)
  if (.hasSlot(x, 'coords')) {
    crds <- x@coords  
  } else crds <- x
  z <- deldir(crds[,1], crds[,2])
  w <- tile.list(z)
  polys <- vector(mode='list', length=length(w))
  require(sp)
  for (i in seq(along=polys)) {
    pcrds <- cbind(w[[i]]$x, w[[i]]$y)
    pcrds <- rbind(pcrds, pcrds[1,])
    polys[[i]] <- Polygons(list(Polygon(pcrds)), ID=as.character(i))
  }
  SP <- SpatialPolygons(polys)
  voronoi <- SpatialPolygonsDataFrame(SP, data=data.frame(x=crds[,1],
    y=crds[,2], row.names=sapply(slot(SP, 'polygons'), 
    function(x) slot(x, 'ID'))))
}

# rg0911 <- readOGR("shapefiles","RainGauges2009_2011")
# summary(rg0911)
# v <- voronoipolygons(rg0911)
# summary(v)
# plot(v)
# plot(rg0911, add = TRUE)
```

Proof that it works, but I think I need to do this to the subset for each season so that only points with observations are used. I should end up with 10 surfaces with varying numbers of polygons depending on how many sites were `NA` or removed b/c outliers for that season.

```{r create season Thiessen polys}
library(rgdal); library(dismo)
rainy04v <- voronoi(rainy04 <- readOGR(dsn = "shapefiles", layer = "rain_gauges04"))
rainy05v <- voronoi(rainy05 <- readOGR(dsn = "shapefiles", layer = "rain_gauges05"))
rainy06v <- voronoi(rainy06 <- readOGR(dsn = "shapefiles", layer = "rain_gauges06"))
rainy07v <- voronoi(rainy07 <- readOGR(dsn = "shapefiles", layer = "rain_gauges07"))
rainy08v <- voronoi(rainy08 <- readOGR(dsn = "shapefiles", layer = "rain_gauges08"))

rainy09v <- voronoi(rainy09 <- readOGR(dsn = "shapefiles", layer = "rain_gauges09"))
rainy10v <- voronoi(rainy10 <- readOGR(dsn = "shapefiles", layer = "rain_gauges10"))
rainy11v <- voronoi(rainy11 <- readOGR(dsn = "shapefiles", layer = "rain_gauges11"))
rainy12v <- voronoi(rainy12 <- readOGR(dsn = "shapefiles", layer = "rain_gauges12"))
rainy14v <- voronoi(rainy14 <- readOGR(dsn = "shapefiles", layer = "rain_gauges14"))
```

Overlay Thiessen polygons and plot locations
```{r overlay plots and Thiessen polys}
library(rgdal)
plts <- readOGR(dsn = "shapefiles", layer = "soco_plots_metric")
str(plts)
str(rainy04)
plts <- spTransform(plts, CRS=crs)
all.equal.default(proj4string(plts), proj4string(rainy04v), proj4string(rainy05v))

plot(elev, main = "2004 Rain Thiessens"); plot(plts, add = T, pch = 21); plot(rainy04, add = T, pch = 25, col = "blue"); plot(rainy04v, axes = T, add=T) 

summary(rainy05v)
plot(rainy05v, axes = T, main = "2005 Rain Thiessens"); plot(plts, add = T); plot(rainy05, add = T, col = "blue", pch = 25)

plot(rainy06v, axes = T, main = "2006 Rain Thiessens"); plot(plts, add = T); plot(rainy06, add = T, col = "blue", pch = 25)

plot(rainy07v, axes = T, main = "2007 Rain Thiessens"); plot(plts, add = T); plot(rainy07, add = T, col = "blue", pch = 25)

plot(rainy08v, axes = T, main = "2008 Rain Thiessens"); plot(plts, add = T); plot(rainy08, add = T, col = "blue", pch = 25)

plot(rainy09v, axes = T, main = "2009 Rain Thiessens"); plot(plts, add = T); plot(rainy09, add = T, col = "blue", pch = 25)

plot(rainy10v, axes = T, main = "2010 Rain Thiessens"); plot(plts, add = T); plot(rainy10, add = T, col = "blue", pch = 25)

plot(rainy11v, axes = T, main = "2011 Rain Thiessens"); plot(plts, add = T); plot(rainy11, add = T, col = "blue", pch = 25)

plot(rainy12v, axes = T, main = "2012 Rain Thiessens"); plot(plts, add = T); plot(rainy12, add = T, col = "blue", pch = 25)

plot(rainy14v, axes = T, main = "2014 Rain Thiessens"); plot(plts, add = T); plot(rainy14, add = T, col = "blue", pch = 25)
```

The voronoi (Thiessen) polygons don't extend to the edges of the extent as it is shrunk when the rain gauge station dataset is reduced around the edges. The bounding box appears to be based on the min-max of the `x` and `y` coordinates. It looks like none of them quite cover all of the plot point locations, but they would all be covered by the elevation surface.  

How do I extend the `bbox` of the point shapefiles to the elevation surface extent and have that captured by the `voronoi` function?

```{r extend bbox}
bbox(elev)
bbox(rainy04)
all.equal(proj4string(elev), proj4string(rainy04))
elev@extent
new_bbox <- bbox(elev)
rainy04@bbox <- new_bbox
bbox(rainy04)
test <- voronoi(rainy04)
plot(test); plot(plts, add = T)
extent(rainy04)
```

Since the `voronoi` function pulls the point coordinates explicitly it is apparent that this won't work the way I want it to.


Developing a linear model for kriging
```{r rk model jan 2008}
rg_0108 <- subset(rg_2003_2008@data, year==2008 & month==1)
coordinates(rg_0108) = ~NORTHING+EASTING
str(rg_0108)
#rg_2003_2008 <- readOGR(dsn="shapefiles", layer="RainGauges2003_2008")
#rg_2003_2008 <- spTransform(rg_2003_2008, CRS=crs)
rg_0108@proj4string <- rg_2003_2008@proj4string
rg_0108 <- spTransform(rg_0108, CRS=crs)

# elev_ppt <- overlay(as(elev, "SpatialGridDataFrame"), rg_0108)   # create grid-points overlay
   # copy the slope values
lm_rg_0108 <- lm(daily_ppt ~ elev_m, rg_0108)# This is certainly incorrect b/c precipitation constrained to be >= 0 
summary(lm_rg_0108)
plot(lm_rg_0108)

plot(log(rg_0108$elev_m), log1p(rg_0108$daily_ppt))
lm_rg_0108a <- lm((daily_ppt) ~ elev_m, data = rg_0108@data %>% filter(NAME != "backman", day == 31))
summary(lm_rg_0108a)
```


```{r thin plate spline example}
library(fields)
loc_matrix <- cbind(rg_0108$NORTHING,rg_0108$EASTING)
ppt <- (rg_0108$daily_ppt)
jan08tps <- Tps(loc_matrix, ppt)
summary(jan08tps)
plot(jan08tps)
surface(jan08tps)

look <- predict(jan08tps, lambda = 2.0)
look <- predict(jan08tps, df = 4)

tps1 <- Tps(loc_matrix, ppt, df = 4)
summary(tps1)
set.panel(2,2)
plot(tps1)
set.panel()

out_jan08 <- predictSurface(jan08tps)
image(out_jan08)

# fit <- Tps(ozone$x, ozone$y)
# set.panel(2,2)
# plot(fit)
```
